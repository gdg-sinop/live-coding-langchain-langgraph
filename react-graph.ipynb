{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caa33687",
   "metadata": {},
   "source": [
    "# ReAct Agent - LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6466ef",
   "metadata": {},
   "source": [
    "Similar a arquitetura ReAct do create_agent do langchain, vamos construir step-by-step nosso loop ReAct com langgraph. \n",
    "\n",
    "(pensar->agir->observar->responder)\n",
    "\n",
    "![Screenshot 2024-08-21 at 12.45.32 PM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab7453080e6802cd1703_agent-memory1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "051caa4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bf70d8",
   "metadata": {},
   "source": [
    "## Definição de tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53926336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "# This will be a tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a / b\n",
    "\n",
    "\n",
    "tools = [add, multiply, divide]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d04409",
   "metadata": {},
   "source": [
    "## Iniciando o chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eb8a1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(model=\"gpt-4.1-mini\")\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d4f131",
   "metadata": {},
   "source": [
    "## State + Prompt + Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31abc4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# System message\n",
    "sys_msg = SystemMessage(content=\"Você é um assistente encarregado de realizar operações aritméticas em um conjunto de entradas.\")\n",
    "\n",
    "# Node\n",
    "def assistant(state: MessagesState):\n",
    "   return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae20e58c",
   "metadata": {},
   "source": [
    "## definindo o grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1447d345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10ee30620>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define nodes\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Define edges\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # Se a ultima mensagem (result) do assistant é uma tool call -> tools_condition roteia para tools\n",
    "    # Se a ultima mensagem (result) do assistant não é uma tool call -> tools_condition roteia para END\n",
    "    tools_condition,\n",
    ")\n",
    "# Retorna a resposta para o modelo (observe)\n",
    "builder.add_edge(\"tools\", \"assistant\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc517d30",
   "metadata": {},
   "source": [
    "## Memory "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e580f7fd",
   "metadata": {},
   "source": [
    "Pra usar memoria, precisamos especificar um `thread_id`.\n",
    "\n",
    "![state.jpg](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e0e9f526b41a4ed9e2d28b_agent-memory2.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b2768f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ae9441b",
   "metadata": {},
   "outputs": [],
   "source": [
    "react_graph_memory = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3eabbf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Faça a soma de 3 e 4.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_LrvSiiwZnBXWnbEaJg8V0uU4)\n",
      " Call ID: call_LrvSiiwZnBXWnbEaJg8V0uU4\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "7\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "A soma de 3 e 4 é 7. Posso ajudar com mais alguma coisa?\n"
     ]
    }
   ],
   "source": [
    "# Specify a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Specify an input\n",
    "messages = [HumanMessage(content=\"Faça a soma de 3 e 4.\")]\n",
    "\n",
    "# Run\n",
    "messages = react_graph_memory.invoke({\"messages\": messages},config)\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2fb5c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Faça a soma de 3 e 4.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_LrvSiiwZnBXWnbEaJg8V0uU4)\n",
      " Call ID: call_LrvSiiwZnBXWnbEaJg8V0uU4\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "7\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "A soma de 3 e 4 é 7. Posso ajudar com mais alguma coisa?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiplique o resultado por 2.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_4sH6j5R5n7zb4PWjMdyi9MOQ)\n",
      " Call ID: call_4sH6j5R5n7zb4PWjMdyi9MOQ\n",
      "  Args:\n",
      "    a: 7\n",
      "    b: 2\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "14\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "O resultado da multiplicação de 7 por 2 é 14. Gostaria de realizar mais alguma operação?\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Multiplique o resultado por 2.\")]\n",
    "messages = react_graph_memory.invoke({\"messages\": messages}, config)\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
